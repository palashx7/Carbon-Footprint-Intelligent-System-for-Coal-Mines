{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZLG7rAdPs0r5"
   },
   "source": [
    "Dataset Making"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4ajLsYxWs3C5",
    "outputId": "b429083c-e6f5-4679-db96-0f66020381a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset generated and saved as 'synthetic_carbon_credit_data_200k.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# Define the number of samples\n",
    "num_samples = 200000\n",
    "\n",
    "# Define the possible values for categorical features\n",
    "offset_methods = ['Afforestation', 'Renewable Energy', 'Energy Efficiency', 'Reforestation']\n",
    "project_locations = ['India', 'USA', 'China', 'Brazil']\n",
    "verification_statuses = ['Verified', 'Pending', 'Rejected']\n",
    "technologies_used = ['Solar', 'Wind', 'Hydro', 'Biomass']\n",
    "\n",
    "# Generate random data\n",
    "np.random.seed(42)\n",
    "data = {\n",
    "    'OffsetMethod': np.random.choice(offset_methods, num_samples),\n",
    "    'ProjectLocation': np.random.choice(project_locations, num_samples),\n",
    "    'VerificationStatus': np.random.choice(verification_statuses, num_samples),\n",
    "    'TechnologyUsed': np.random.choice(technologies_used, num_samples),\n",
    "    'EmissionReduction': np.random.uniform(100, 10000, num_samples),\n",
    "    'ProjectSize': np.random.uniform(1, 1000, num_samples)\n",
    "}\n",
    "\n",
    "# Calculate the carbon credit price based on a linear combination of the factors\n",
    "# Coefficients are assumed for demonstration purposes and should be adjusted based on domain knowledge\n",
    "coefficients = {\n",
    "    'EmissionReduction': 0.005,\n",
    "    'ProjectSize': 0.01,\n",
    "    'OffsetMethod': {'Afforestation': 10, 'Renewable Energy': 20, 'Energy Efficiency': 15, 'Reforestation': 12},\n",
    "    'ProjectLocation': {'India': 5, 'USA': 10, 'China': 8, 'Brazil': 6},\n",
    "    'VerificationStatus': {'Verified': 10, 'Pending': 5, 'Rejected': -5},\n",
    "    'TechnologyUsed': {'Solar': 8, 'Wind': 7, 'Hydro': 6, 'Biomass': 5}\n",
    "}\n",
    "\n",
    "# Apply the coefficients to calculate the carbon credit price\n",
    "carbon_credit_price = (\n",
    "    coefficients['EmissionReduction'] * data['EmissionReduction'] +\n",
    "    coefficients['ProjectSize'] * data['ProjectSize'] +\n",
    "    [coefficients['OffsetMethod'][method] for method in data['OffsetMethod']] +\n",
    "    [coefficients['ProjectLocation'][location] for location in data['ProjectLocation']] +\n",
    "    [coefficients['VerificationStatus'][status] for status in data['VerificationStatus']] +\n",
    "    [coefficients['TechnologyUsed'][tech] for tech in data['TechnologyUsed']]\n",
    ")\n",
    "\n",
    "data['CarbonCreditPrice'] = carbon_credit_price\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('synthetic_carbon_credit_data_200k.csv', index=False)\n",
    "\n",
    "print(\"Dataset generated and saved as 'synthetic_carbon_credit_data_200k.csv'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BPPBhmaTs4w3"
   },
   "source": [
    "Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "en99FStUs6O9",
    "outputId": "c79d4e64-23d3-469f-ca9d-e4e80d0adaba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.2173391013940758\n",
      "R^2 Score: 0.9991988171761845\n",
      "Model trained and saved as 'carbon_credit_price_model1.pkl'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import joblib\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('synthetic_carbon_credit_data_200k.csv')\n",
    "\n",
    "# Define the features and target variable\n",
    "X = df.drop(columns=['CarbonCreditPrice'])\n",
    "y = df['CarbonCreditPrice']\n",
    "\n",
    "# Identify categorical and numerical columns\n",
    "categorical_cols = ['OffsetMethod', 'ProjectLocation', 'VerificationStatus', 'TechnologyUsed']\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "# Preprocessing for numerical data: scaling\n",
    "numerical_transformer = StandardScaler()\n",
    "\n",
    "# Preprocessing for categorical data: one-hot encoding\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# Bundle preprocessing for numerical and categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])\n",
    "\n",
    "# Define the model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Create and evaluate the pipeline\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('model', model)\n",
    "                          ])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'R^2 Score: {r2}')\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(pipeline, 'carbon_credit_price_model1.pkl')\n",
    "\n",
    "print(\"Model trained and saved as 'carbon_credit_price_model1.pkl'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DUK1qbbGtEQ8"
   },
   "source": [
    "Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mzd05crgtIsM",
    "outputId": "ea5fb7d3-7767-4011-c0ed-a88ac0313e1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Carbon Credit Price: ₹4953.96\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "# Load the trained model\n",
    "model = joblib.load('carbon_credit_price_model1.pkl')\n",
    "\n",
    "# Define a function to predict carbon credit price based on user inputs\n",
    "def predict_carbon_credit_price(offset_method, project_location, verification_status, technology_used, emission_reduction, project_size):\n",
    "    # Create a DataFrame with the user inputs\n",
    "    data = {\n",
    "        'OffsetMethod': [offset_method],\n",
    "        'ProjectLocation': [project_location],\n",
    "        'VerificationStatus': [verification_status],\n",
    "        'TechnologyUsed': [technology_used],\n",
    "        'EmissionReduction': [emission_reduction],\n",
    "        'ProjectSize': [project_size]\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Make the prediction\n",
    "    predicted_price = model.predict(df)\n",
    "\n",
    "    return predicted_price[0]\n",
    "\n",
    "# Example usage\n",
    "offset_method = 'Afforestation'\n",
    "project_location = 'India'\n",
    "verification_status = 'Verified'\n",
    "technology_used = 'Solar'\n",
    "emission_reduction = 5000\n",
    "project_size = 100\n",
    "\n",
    "predicted_price = predict_carbon_credit_price(offset_method, project_location, verification_status, technology_used, emission_reduction, project_size)\n",
    "predicted_price = predicted_price * 81\n",
    "print(f'Predicted Carbon Credit Price: ₹{predicted_price:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model and label encoder\n",
    "with open('carbonCreditPrice1.pkl', 'wb') as model_file:\n",
    "    pickle.dump(model, model_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
